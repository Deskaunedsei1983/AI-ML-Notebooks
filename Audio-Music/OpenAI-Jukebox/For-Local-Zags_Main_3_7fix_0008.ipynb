{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAGS4j8u0gdN",
    "outputId": "399f5e56-9762-4061-c24c-9d8ae9d21c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: GeForce RTX 3090 (UUID: GPU-87528f9a-bbaf-944b-38fc-e6a9a5cc6923)\n",
      "Python 3.9.6\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L\n",
    "!python3 -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAGS4aH_BPGN",
    "outputId": "2eb0fd4e-b276-4493-bb3d-e6b1f9e77e14"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LtK7KvgqCI-k"
   },
   "outputs": [],
   "source": [
    "# Stopped mid level = 2? use continue\n",
    "# Stopped mid level = 1 or 0? use upsample\n",
    "\n",
    "lemode = 'upsample'     # 'ancestral','primed','continue','cutcontinue','upsample'\n",
    "lemodel = '5b_lyrics'                          #5b_lyrics or '5b' or '1b_lyrics'\n",
    "\n",
    "lecount = 9 #orig 3\n",
    "lesample_length_in_seconds = 240\n",
    "lesampling_temperature = .989\n",
    "lehop = [.75,1,.125]                 #default [.5,.5,.125], optimized [1,1,0.0625] #[.75,1,.125] [.5,.5,.125] [1,1,.0625]\n",
    "\n",
    "lepath = './Ai001/com39008/Ai-Create'\n",
    "\n",
    "leprompt_length_in_seconds=15  \n",
    "leaudio_file = '/venvs/venv-ub20/py39001/Ai001/Billy-Ocean-Loverboy-HQ-MidStart01.wav'                    \n",
    "\n",
    "lecut = 70               # used only on cutcontinue\n",
    "transpose = [0,1,2]      # used only on cutcontinue [0,1,2] = default, ex [1,1,1] all samples are copied from item 1\n",
    "\n",
    "leexportlyrics = True\n",
    "leprogress = True\n",
    "leautorename = True\n",
    "\n",
    "leartist = \"billy ocean\"\n",
    "legenre = \"pop dance\"\n",
    "legenre2 = \"pop dance funk\"\n",
    "legenre3 = \"pop disco dance funk\"\n",
    "lelyrics = \"\"\"One ticket, please\n",
    "Lord have mercy, everybody's there\n",
    "Hey, what's goin' on man, yeah\n",
    "She's at home, yeah, she's at home\n",
    "Yeah, she's at home\n",
    "\n",
    "Let the music play\n",
    "I just wanna dance the night away\n",
    "Here, right here, right here is where I'm gonna stay\n",
    "All night long...\n",
    "\n",
    "Let the music play on\n",
    "Just until I feel this misery is gone\n",
    "Movin', kickin', groovin', keep the music strong\n",
    "On and on, and on, and on, and on, and on, and on, and on, and on, and on, and on, and on, and on, and on\n",
    "\n",
    "I'm out here dancin' and still, huh\n",
    "I can't erase the things I feel\n",
    "The tender love we used to share\n",
    "See, it's like it's no longer there\n",
    "I've got to hide what's killin' me inside\n",
    "\n",
    "Let the music play\n",
    "I just want to dance the night away\n",
    "Here, right here, right here is where I'm gonna stay\n",
    "All night long...\n",
    "\n",
    "Let the music play on\n",
    "Just until I feel this misery is gone\n",
    "Ah, movin', kickin', groovin', keep the music strong\n",
    "Ah, let it play on and on, let it play on and on\n",
    "And on, and on, and on, and on, play on and on, play\n",
    "\n",
    "I think I'm gonna be alright, ha, ha, ha\n",
    "If I can make it through the night, oh, Lord\n",
    "I'll just pretend she's here with me\n",
    "I'll close my eyes, her face I'll see\n",
    "I know it's make believe, but it's the only hope for me\n",
    "\n",
    "Let the music play\n",
    "I just wanna dance the night away\n",
    "Ah, here, right here is where I'm gonna stay\n",
    "All night long...\n",
    "\n",
    "Let the music play on\n",
    "Just until I feel this misery is gone\n",
    "Movin', kickin', groovin', keep the music strong\n",
    "Let it play on, let it play on, let it play on\n",
    "Please, let it play on, let it play on\n",
    "\"\"\"\n",
    "\n",
    "lechunk_size = 16  #orig 16\n",
    "lemax_batch_size = 2 #orig lecount or 3\n",
    "lelower_batch_size = lechunk_size\n",
    "lelower_level_chunk_size = lechunk_size * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-8cvPn3CO4s"
   },
   "source": [
    "# 1 Sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZAGS4k1WCC_C",
    "outputId": "65db1e2b-e495-48d5-ef92-cce3523c9350"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (1.1.0)\n",
      "Requirement already satisfied: librosa==0.7.2 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (0.7.2)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from librosa==0.7.2) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.12 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from librosa==0.7.2) (1.0.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from librosa==0.7.2) (0.2.2)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from librosa==0.7.2) (0.10.3.post1)\n",
      "Requirement already satisfied: six>=1.3 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from librosa==0.7.2) (1.16.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from librosa==0.7.2) (2.1.9)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from librosa==0.7.2) (5.1.0)\n",
      "Requirement already satisfied: numba>=0.43.0 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from librosa==0.7.2) (0.48.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from librosa==0.7.2) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from librosa==0.7.2) (1.21.2)\n",
      "Requirement already satisfied: setuptools in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from numba>=0.43.0->librosa==0.7.2) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.7.2) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /venvs/venv-ub20/py39001/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)\n",
      "Collecting git+https://github.com/openai/jukebox.git\n",
      "  Cloning https://github.com/openai/jukebox.git to /tmp/pip-req-build-2pstds42\n",
      "  Running command git clone -q https://github.com/openai/jukebox.git /tmp/pip-req-build-2pstds42\n",
      "  Resolved https://github.com/openai/jukebox.git to commit 08efbbc1d4ed1a3cef96e08a931944c8b4d63bb3\n",
      "Collecting fire==0.1.3\n",
      "  Using cached fire-0.1.3-py2.py3-none-any.whl\n",
      "Collecting tqdm==4.45.0\n",
      "  Using cached tqdm-4.45.0-py2.py3-none-any.whl (60 kB)\n",
      "Collecting soundfile==0.10.3.post1\n",
      "  Using cached SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting unidecode==1.1.1\n",
      "  Using cached Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
      "Collecting numba==0.48.0\n",
      "  Using cached numba-0.48.0-cp39-cp39-linux_x86_64.whl\n",
      "Collecting librosa==0.7.2\n",
      "  Using cached librosa-0.7.2-py3-none-any.whl\n",
      "Collecting mpi4py>=3.0.0\n",
      "  Using cached mpi4py-3.1.1-cp39-cp39-linux_x86_64.whl\n",
      "Collecting six\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting decorator>=3.0.0\n",
      "  Using cached decorator-5.1.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting scikit-learn!=0.19.0,>=0.14.0\n",
      "  Using cached scikit_learn-0.24.2-cp39-cp39-manylinux2010_x86_64.whl (23.8 MB)\n",
      "Collecting scipy>=1.0.0\n",
      "  Using cached scipy-1.7.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.5 MB)\n",
      "Collecting audioread>=2.0.0\n",
      "  Using cached audioread-2.1.9-py3-none-any.whl\n",
      "Collecting joblib>=0.12\n",
      "  Using cached joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "Collecting resampy>=0.2.2\n",
      "  Using cached resampy-0.2.2-py3-none-any.whl\n",
      "Collecting numpy>=1.15.0\n",
      "  Using cached numpy-1.21.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.8 MB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-58.0.4-py3-none-any.whl (816 kB)\n",
      "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
      "  Using cached llvmlite-0.31.0-cp39-cp39-linux_x86_64.whl\n",
      "Collecting cffi>=1.0\n",
      "  Using cached cffi-1.14.6-cp39-cp39-manylinux1_x86_64.whl (405 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: jukebox\n",
      "  Building wheel for jukebox (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jukebox: filename=jukebox-1.0-py3-none-any.whl size=191326 sha256=ba20209a804c33e7e38d18bce887973b39c97cbadad1e8b32771532a9d3c1fa3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uykq9v5l/wheels/71/d3/da/22e7118b918f3ec3da265e3e8007060959339c21c9e13f444a\n",
      "Successfully built jukebox\n",
      "Installing collected packages: setuptools, pycparser, numpy, llvmlite, threadpoolctl, six, scipy, numba, joblib, cffi, soundfile, scikit-learn, resampy, decorator, audioread, unidecode, tqdm, mpi4py, librosa, fire, jukebox\n",
      "Successfully installed audioread-2.1.9 cffi-1.14.6 decorator-5.1.0 fire-0.1.3 joblib-1.0.1 jukebox-1.0 librosa-0.7.2 llvmlite-0.31.0 mpi4py-3.1.1 numba-0.48.0 numpy-1.21.2 pycparser-2.20 resampy-0.2.2 scikit-learn-0.24.2 scipy-1.7.1 setuptools-58.0.4 six-1.16.0 soundfile-0.10.3.post1 threadpoolctl-2.2.0 tqdm-4.45.0 unidecode-1.1.1\n",
      "Using cuda True\n",
      "07:14:17\n",
      "Downloading from azure\n",
      "Restored from /root/.cache/jukebox/models/5b/vqvae.pth.tar\n",
      "0: Loading vqvae in eval mode\n",
      "Loading artist IDs from /venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/data/ids/v2_artist_ids.txt\n",
      "Loading artist IDs from /venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/data/ids/v2_genre_ids.txt\n",
      "Level:2, Cond downsample:None, Raw to tokens:128, Sample length:1048576\n",
      "0: Converting to fp16 params\n",
      "Downloading from azure\n",
      "Restored from /root/.cache/jukebox/models/5b_lyrics/prior_level_2.pth.tar\n",
      "0: Loading prior in eval mode\n",
      "upsampleing from level 2\n",
      "mode is now upsample\n",
      "Falling through to the upsample step later in the notebook.\n",
      "07:14:56\n"
     ]
    }
   ],
   "source": [
    "if lemode=='ancestral':\n",
    "  leprompt_length_in_seconds=None  \n",
    "  leaudio_file = None\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "\n",
    "codes_file=None\n",
    "\n",
    "#!rm -rf /venvs/vens-ub20/py39002/lib/python3.9/site-packages/jukebox/\n",
    "#!rm -rf /venvs/vens-ub20/py39002/lib/python3.9/site-packages/jukebox-1.0.dist-info/\n",
    "#!pip install llvmlite==0.32 --ignore-installed\n",
    "!pip install termcolor\n",
    "!pip install librosa==0.7.2\n",
    "!pip install soundfile>=0.9.0\n",
    "!pip install git+https://github.com/openai/jukebox.git --ignore-installed\n",
    "\n",
    "##$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#### autosave start\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "filex = \"/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/sample.py\"\n",
    "fin = open(filex, \"rt\")\n",
    "data = fin.read()\n",
    "fin.close()\n",
    "\n",
    "newtext = '''import fire\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from termcolor import colored\n",
    "from datetime import datetime\n",
    "\n",
    "newtosample = True'''\n",
    "data = data.replace('import fire',newtext)\n",
    "\n",
    "newtext = '''starts = get_starts(total_length, prior.n_ctx, hop_length)\n",
    "        counterr = 0\n",
    "        x = None\n",
    "        for start in starts:'''\n",
    "data = data.replace('for start in get_starts(total_length, prior.n_ctx, hop_length):',newtext)\n",
    "\n",
    "newtext = '''global newtosample\n",
    "    newtosample = (new_tokens > 0)\n",
    "    if new_tokens <= 0:'''\n",
    "data = data.replace('if new_tokens <= 0:',newtext)\n",
    "\n",
    "newtext = '''counterr += 1\n",
    "            datea = datetime.now()\t\t\n",
    "            zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)\t\t\t\n",
    "            if newtosample and counterr < len(starts):\n",
    "                del x; x = None; prior.cpu(); empty_cache()\n",
    "                x = prior.decode(zs[level:], start_level=level, bs_chunks=zs[level].shape[0])\n",
    "                logdir = f\"{hps.name}/level_{level}\"\n",
    "                if not os.path.exists(logdir):\n",
    "                    os.makedirs(logdir)\n",
    "                t.save(dict(zs=zs, labels=labels, sampling_kwargs=sampling_kwargs, x=x), f\"{logdir}/data.pth.tar\")\n",
    "                save_wav(logdir, x, hps.sr)\n",
    "                del x; prior.cuda(); empty_cache(); x = None\n",
    "            dateb = datetime.now()\n",
    "            timex = ((dateb-datea).total_seconds()/60.0)*(len(starts)-counterr)\n",
    "            print(f\"Step \" + colored(counterr,'blue') + \"/\" + colored( len(starts),'red') + \" ~ New to Sample: \" + str(newtosample) + \" ~ estimated remaining minutes: \" + (colored('???','yellow'), colored(timex,'magenta'))[counterr > 1 and newtosample])'''\n",
    "data = data.replace('zs = sample_single_window(zs, labels, sampling_kwargs, level, prior, start, hps)',newtext)\n",
    "\n",
    "\n",
    "newtext = \"\"\"lepath=hps.name\n",
    "        if level==2:\n",
    "          for filex in glob(os.path.join(lepath + '/level_2','item_*.wav')):\n",
    "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-'))\n",
    "        if level==1:\n",
    "          for filex in glob(os.path.join(lepath + '/level_1','item_*.wav')):\n",
    "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-L1-'))\n",
    "        if level==0:\n",
    "          for filex in glob(os.path.join(lepath + '/level_0','item_*.wav')):\n",
    "            os.rename(filex,filex.replace('item_',lepath.split('/')[-1] + '-L0-'))\n",
    "        save_html(\"\"\"\n",
    "if leautorename:\n",
    "  data = data.replace('save_html(',newtext)\n",
    "\n",
    "if leexportlyrics == False:\n",
    "  data = data.replace('if alignments is None','#if alignments is None')\n",
    "  data = data.replace('alignments = get_alignment','#alignments = get_alignment')\n",
    "  data = data.replace('save_html(','#save_html(')\n",
    "\n",
    "if leprogress == False:\n",
    "  data = data.replace('print(f\"Step \" +','#print(f\"Step \" +')\n",
    "  \n",
    "fin = open(filex, \"wt\")\n",
    "fin.write(data)\n",
    "fin.close()\n",
    "##$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$#### autosave end\n",
    "\n",
    "import jukebox\n",
    "import torch as t\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import Audio\n",
    "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
    "from jukebox.hparams import Hyperparams, setup_hparams\n",
    "from jukebox.sample import sample_single_window, _sample, \\\n",
    "                           sample_partial_window, upsample, \\\n",
    "                           load_prompts\n",
    "from jukebox.utils.dist_utils import setup_dist_from_mpi\n",
    "from jukebox.utils.torch_utils import empty_cache\n",
    "rank, local_rank, device = setup_dist_from_mpi()\n",
    "\n",
    "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "model = lemodel\n",
    "hps = Hyperparams()\n",
    "hps.sr = 44100\n",
    "hps.n_samples = lecount \n",
    "hps.name = lepath\n",
    "\n",
    "chunk_size = lechunk_size\n",
    "max_batch_size = lemax_batch_size\n",
    "\n",
    "hps.levels = 3\n",
    "hps.hop_fraction = lehop\n",
    "\n",
    "vqvae, *priors = MODELS[model]\n",
    "vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
    "top_prior = make_prior(setup_hparams(priors[-1], dict()), vqvae, device)\n",
    "\n",
    "# Prime song creation using an arbitrary audio sample.\n",
    "mode = lemode\n",
    "codes_file=None\n",
    "audio_file = leaudio_file\n",
    "prompt_length_in_seconds=leprompt_length_in_seconds\n",
    "\n",
    "\n",
    "if os.path.exists(hps.name):\n",
    "  # Identify the lowest level generated and continue from there.\n",
    "  for level in [0, 1, 2]:\n",
    "    data = f\"{hps.name}/level_{level}/data.pth.tar\"\n",
    "    if os.path.isfile(data):\n",
    "      mode = mode if 'continue' in mode else 'upsample'\n",
    "      codes_file = data\n",
    "      print(mode + 'ing from level ' + str(level))\n",
    "      break\n",
    "print('mode is now '+mode)\n",
    "\n",
    "sample_hps = Hyperparams(dict(mode=mode, codes_file=codes_file, audio_file=audio_file, prompt_length_in_seconds=prompt_length_in_seconds))\n",
    "\n",
    "sample_length_in_seconds = lesample_length_in_seconds \n",
    "hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
    "assert hps.sample_length >= top_prior.n_ctx*top_prior.raw_to_tokens, f'Please choose a larger sampling rate'\n",
    "\n",
    "metas = [dict(artist = leartist,\n",
    "            genre = legenre,\n",
    "            total_length = hps.sample_length,\n",
    "            offset = 0,\n",
    "            lyrics = lelyrics,\n",
    "            ),\n",
    "          ] * hps.n_samples\n",
    "labels = [None, None, top_prior.labeller.get_batch_labels(metas, 'cuda')]\n",
    "\n",
    "\n",
    "#----------------------------------------------------------2\n",
    "\n",
    "\n",
    "sampling_temperature = lesampling_temperature\n",
    "lower_batch_size = lelower_batch_size\n",
    "max_batch_size = lemax_batch_size\n",
    "lower_level_chunk_size = lelower_level_chunk_size\n",
    "chunk_size = lechunk_size \n",
    "sampling_kwargs = [dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
    "                        chunk_size=lower_level_chunk_size),\n",
    "                    dict(temp=.99, fp16=True, max_batch_size=lower_batch_size,\n",
    "                         chunk_size=lower_level_chunk_size),\n",
    "                    dict(temp=sampling_temperature, fp16=True, \n",
    "                         max_batch_size=max_batch_size, chunk_size=chunk_size)]\n",
    "\n",
    "if sample_hps.mode == 'ancestral':\n",
    "  zs = [t.zeros(hps.n_samples,0,dtype=t.long, device='cuda') for _ in range(len(priors))]\n",
    "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
    "elif sample_hps.mode == 'upsample':\n",
    "  assert sample_hps.codes_file is not None\n",
    "  # Load codes.\n",
    "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
    "  zs = [z.cuda() for z in data['zs']]\n",
    "  assert zs[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
    "  del data\n",
    "  print('Falling through to the upsample step later in the notebook.')\n",
    "elif sample_hps.mode == 'primed':\n",
    "  assert sample_hps.audio_file is not None\n",
    "  audio_files = sample_hps.audio_file.split(',')\n",
    "  duration = (int(sample_hps.prompt_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
    "  x = load_prompts(audio_files, duration, hps)\n",
    "  zs = top_prior.encode(x, start_level=0, end_level=len(priors), bs_chunks=x.shape[0])\n",
    "  print(sample_hps.prompt_length_in_seconds)\n",
    "  print(hps.sr)\n",
    "  print(top_prior.raw_to_tokens)\n",
    "  print('aaaaaaaaaaaaaaaaaaaaaaaaaaaa 4.52')\n",
    "  print(duration)\n",
    "  print(audio_files)\n",
    "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
    "elif sample_hps.mode == 'continue':\n",
    "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
    "  zs = [z.cuda() for z in data['zs']]\n",
    "  zs = _sample(zs, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
    "elif sample_hps.mode == 'cutcontinue':\n",
    "  print('-------CUT INIT--------')\n",
    "  lecutlen = (int(lecut*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
    "  print(lecutlen)\n",
    "  data = t.load(codes_file, map_location='cpu')\n",
    "  zabaca = [z.cuda() for z in data['zs']]\n",
    "  print(zabaca)\n",
    "  assert zabaca[-1].shape[0] == hps.n_samples, f\"Expected bs = {hps.n_samples}, got {zs[-1].shape[0]}\"\n",
    "  priorsz = [top_prior] * 3\n",
    "  top_raw_to_tokens = priorsz[-1].raw_to_tokens\n",
    "  assert lecutlen % top_raw_to_tokens == 0, f\"Cut-off duration {lecutlen} not an exact multiple of top_raw_to_tokens\"\n",
    "  assert lecutlen//top_raw_to_tokens <= zabaca[-1].shape[1], f\"Cut-off tokens {lecutlen//priorsz[-1].raw_to_tokens} longer than tokens {zs[-1].shape[1]} in saved codes\"\n",
    "  zabaca = [z[:,:lecutlen//prior.raw_to_tokens] for z, prior in zip(zabaca, priorsz)]\n",
    "  hps.sample_length = lecutlen\n",
    "  print(zabaca)\n",
    "  zs = _sample(zabaca, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
    "  del data\n",
    "  print('-------CUT OK--------')\n",
    "  hps.sample_length = (int(sample_length_in_seconds*hps.sr)//top_prior.raw_to_tokens)*top_prior.raw_to_tokens\n",
    "  data = t.load(sample_hps.codes_file, map_location='cpu')\n",
    "  zibica = [z.cuda() for z in data['zs']]\n",
    "  zubu = zibica[:]\n",
    "  if transpose != [0,1,2]:\n",
    "    zubu[2][0] = zibica[:][2][transpose[0]];zubu[2][1] = zibica[:][2][transpose[1]];zubu[2][2] = zibica[:][2][transpose[2]]\n",
    "    zubu[1][0] = zibica[:][1][transpose[0]];zubu[1][1] = zibica[:][1][transpose[1]];zubu[1][2] = zibica[:][1][transpose[2]]\n",
    "    zubu[0][0] = zibica[:][0][transpose[0]];zubu[0][1] = zibica[:][0][transpose[1]];zubu[0][2] = zibica[:][0][transpose[2]]\n",
    "  zubu = _sample(zubu, labels, sampling_kwargs, [None, None, top_prior], [2], hps)\n",
    "  print('-------CONTINUE AFTER CUT OK--------')\n",
    "  zs = zubu\n",
    "else:\n",
    "  raise ValueError(f'Unknown sample mode {sample_hps.mode}.')\n",
    "\n",
    "\n",
    "\n",
    "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zskzNDQyMjG"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpX3Fw5dL2BV"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAGS4pnjbmI1"
   },
   "source": [
    "# 2 Upsample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZAGS4LolpZ6w"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:14:56\n",
      "Conditioning on 1 above level(s)\n",
      "Checkpointing convs\n",
      "Checkpointing convs\n",
      "Loading artist IDs from /venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/data/ids/v2_artist_ids.txt\n",
      "Loading artist IDs from /venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/data/ids/v2_genre_ids.txt\n",
      "Level:0, Cond downsample:4, Raw to tokens:8, Sample length:65536\n",
      "Downloading from azure\n",
      "Restored from /root/.cache/jukebox/models/5b/prior_level_0.pth.tar\n",
      "0: Loading prior in eval mode\n",
      "Conditioning on 1 above level(s)\n",
      "Checkpointing convs\n",
      "Checkpointing convs\n",
      "Loading artist IDs from /venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/data/ids/v2_artist_ids.txt\n",
      "Loading artist IDs from /venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/data/ids/v2_genre_ids.txt\n",
      "Level:1, Cond downsample:4, Raw to tokens:32, Sample length:262144\n",
      "Downloading from azure\n",
      "Restored from /root/.cache/jukebox/models/5b/prior_level_1.pth.tar\n",
      "0: Loading prior in eval mode\n",
      "Sampling level 1\n",
      "Sampling 8192 tokens for [0,8192]. Conditioning on 8192 tokens\n",
      "Step \u001b[34m1\u001b[0m/\u001b[31m41\u001b[0m ~ New to Sample: False ~ estimated remaining minutes: \u001b[33m???\u001b[0m\n",
      "Sampling 8192 tokens for [8192,16384]. Conditioning on 8192 tokens\n",
      "Step \u001b[34m2\u001b[0m/\u001b[31m41\u001b[0m ~ New to Sample: False ~ estimated remaining minutes: \u001b[33m???\u001b[0m\n",
      "Sampling 8192 tokens for [16384,24576]. Conditioning on 4284 tokens\n",
      "Primed sampling 9 samples with temp=0.99, top_k=0, top_p=0.0\n",
      "134/134 [00:07<00:00, 17.97it/s]\n",
      "3908/3908 [02:47<00:00, 23.28it/s]\n",
      "Step \u001b[34m3\u001b[0m/\u001b[31m41\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m112.55169649999999\u001b[0m\n",
      "Sampling 8192 tokens for [24576,32768]. Conditioning on 0 tokens\n",
      "Ancestral sampling 9 samples with temp=0.99, top_k=0, top_p=0.0\n",
      "8192/8192 [05:48<00:00, 23.51it/s]\n",
      "Step \u001b[34m4\u001b[0m/\u001b[31m41\u001b[0m ~ New to Sample: True ~ estimated remaining minutes: \u001b[35m216.0677678\u001b[0m\n",
      "Sampling 8192 tokens for [32768,40960]. Conditioning on 0 tokens\n",
      "Ancestral sampling 9 samples with temp=0.99, top_k=0, top_p=0.0\n",
      "2848/8192 [02:02<03:50, 23.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79/2269472418.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprior\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mupsamplers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mupsamplers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_prior\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%H:%M:%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/sample.py\u001b[0m in \u001b[0;36mupsample\u001b[0;34m(zs, labels, sampling_kwargs, priors, hps)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0msample_levels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpriors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpriors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_levels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/sample.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(zs, labels, sampling_kwargs, priors, sample_levels, hps)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mtotal_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_length\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_to_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mhop_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhop_fraction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/sample.py\u001b[0m in \u001b[0;36msample_level\u001b[0;34m(zs, labels, sampling_kwargs, level, prior, total_length, hop_length, hps)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mcounterr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mdatea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mzs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_single_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnewtosample\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcounterr\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/sample.py\u001b[0m in \u001b[0;36msample_single_window\u001b[0;34m(zs, labels, sampling_kwargs, level, prior, start, hps)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mz_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mz_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_conds_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_conds_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mz_samples_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_conds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_conds_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msampling_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mz_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_samples_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/prior/prior.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n_samples, z, z_conds, y, fp16, temp, top_k, top_p, chunk_size, sample_tokens)\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0mencoder_kv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoder_kv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mno_past_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                     z = self.prior.sample(n_samples, x_cond, y_cond, encoder_kv, fp16=fp16, temp=temp, top_k=top_k,\n\u001b[0m\u001b[1;32m    277\u001b[0m                                           top_p=top_p, sample_tokens=sample_tokens)\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/prior/autoregressive.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n_samples, x_cond, y_cond, encoder_kv, fp16, temp, top_k, top_p, get_preds, sample_tokens)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_kv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_kv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cond_after_transformer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/transformer/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_kv, sample, fp16, fp16_out)\u001b[0m\n\u001b[1;32m    185\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_kv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_kv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_kv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/transformer/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_kv, sample)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_kv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_kv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/transformer/factored_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, encoder_kv, sample)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcurr_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/transformer/factored_attention.py\u001b[0m in \u001b[0;36mblock_attn\u001b[0;34m(self, q, k, v, sample)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_suff_cache_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{l} != {self._suff_cache_len()}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/transformer/factored_attention.py\u001b[0m in \u001b[0;36mdense_attn\u001b[0;34m(self, query, key, value, sample)\u001b[0m\n\u001b[1;32m    129\u001b[0m                        (), True)\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/venvs/venv-ub20/py39001/lib/python3.9/site-packages/jukebox/transformer/factored_attention.py\u001b[0m in \u001b[0;36m_attn\u001b[0;34m(self, q, k, v, sample)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
    "del top_prior\n",
    "empty_cache()\n",
    "top_prior=None\n",
    "\n",
    "upsamplers = [make_prior(setup_hparams(prior, dict()), vqvae, 'cpu') for prior in priors[:-1]]\n",
    "labels[:2] = [prior.labeller.get_batch_labels(metas, 'cuda') for prior in upsamplers]\n",
    "\n",
    "zs = upsample(zs, labels, sampling_kwargs, [*upsamplers, top_prior], hps)\n",
    "print(datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "history_visible": true,
   "machine_shape": "hm",
   "name": "Zags_Main_3.7fix-0008.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
